#(2)#
ggplot(dia, aes(x=price,y=cut) + geom_bar(stat = "identity",fill=cut)
#(2)#
ggplot(dia, aes(x=price,y=cut)) + geom_bar(stat = "identity",fill=cut)
#(2)#
ggplot(dia, aes(x=price,y=cut)) + geom_bar(stat = "identity",fill=cut,color=cut)
#(2)#
ggplot(dia, aes(x=price,y=cut)) + geom_bar(stat = "identity")
#(2)#
ggplot(dia, aes(x=cut,y=price)) + geom_bar(stat = "identity")
#(2)#
ggplot(dia, aes(x=cut,y=price,fill=cut)) + geom_bar(stat = "identity")
#(3)#
ggplot(dia aes(x=color,y=cut,fill=color)) + geom_bar(stat = "identity")
#(3)#
ggplot(dia, aes(x=color,y=cut,fill=color)) + geom_bar(stat = "identity")
#(2)#
ggplot(dia, aes(x=cut,y=price,fill=cut)) + geom_bar(stat = "identity")
#(3)#
ggplot(dia, aes(x=color,y=cut,fill=color)) + geom_bar(stat = "identity")
#(3)#
dia_f <- dia %>%
group_by(cut) %>%
summarise(color)
dia_f
#(3)#
dia_f <- dia %>%
group_by(cut) %>%
summarise_each(color, price)
###7번###
#(1)#
dia <- diamonds
###7번###
#(1)#
View(dia) <- diamonds
View(dia)
#(3)#
dia_f <- dia %>%
group_by(cut=="Fair") %>%
summarise(color,price)
dia_f
ggplot(dia_f, aes(x=color,y=cut,fill=color)) + geom_bar(stat = "identity")
ggplot(dia_f, aes(x=color,y=price,fill=color)) + geom_bar(stat = "identity")
dia_g <- dia %>%
group_by(cut=="Good") %>%
summarise(color,price)
ggplot(dia_g, aes(x=color,y=price,fill=color)) + geom_bar(stat = "identity")
dia_g
dia_v <- dia %>%
group_by(cut=="Very Good") %>%
summarise(color,price)
ggplot(dia_v, aes(x=color,y=price,fill=color)) + geom_bar(stat = "identity")
#(3)#
dia_f <- dia %>%
group_by(cut=="Fair")
#summarise(color,price)
dia_f
setwd("D:/Workspace/R_Data_Analysis/Part2/stage1/Ex04_jobs")
install.packages("tm")
library(tm)
install.packages("wordcloud2")
data1 <- readLines("tm_test1.txt")
data1
corp1 <- Corpus(VectorSource(data1))
corp1
inspect(corp1)
tdm <- TermDocumentMatrix(corp1)
tdm
m <- as.matrix(tdm)
m
stopwords('en')
data1 <- readLines("steve.txt")
data1
corp1 <- Corpus(VectorSource(data1))
tdm <- TermDocumentMatrix(corp1)
m <- as.matrix(tdm)
colnames(m)
data1 <- readLines("steve.txt")
corp1 <- Corpus(VectorSource(data1))
tdm <- TermDocumentMatrix(corp1)
m <- as.matrix(tdm)
colnames(m)
corp2 <- tm_map(corp1,stripWhitespace)
corp2 <- tm_map(corp2, tolower)
corp2 <- tm_map(corp2,removePunctuation)
stopword2 <- c(stopwords('en'), "and","but")
corp2 <- tm_map(corp2, removeWords,stopword2)
corp3 <- TermDocumentMatrix(corp2, control = list(wordLengths=c(1,lnf)))
library(tm)
library(wordcloud2)
corp3 <- TermDocumentMatrix(corp2, control = list(word=c(1,lnf)))
corp3 <- TermDocumentMatrix(corp2, control = list(word=c(1,Inf)))
corp3
findFreqTerms(corp3,10)
findAssocs(corp3,"apple",0.5)
corp4 <- as.matrix(corp3)
freq1 <- sort(rowSums(corp4),decreasing = T)
freq2 <- sort(colSums(corp4),decreasing = T)
head(freq2,20)
dim(corp4)
colnames(corp4)
freq2 <- sort(colSums(corp4),decreasing = T)
wordcloud2(names(freq1))
wordcloud2(names(freq1),freq=freq1,scale=c(5,1),min.freq=5)
wordcloud1(names(freq1),freq=freq1,scale=c(5,1),min.freq=5)
wordcloud(names(freq1),freq=freq1,scale=c(5,1),min.freq=5)
library(wordcloud)
wordcloud(names(freq1),freq=freq1,scale=c(5,1),min.freq=5)
setwd("D:/Workspace/R_Data_Analysis/Part2/stage1/Ex05_Regex")
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
alert <- readLines("oracle_alert_testdb.log")
error_1 <- gsub(" ", "_",alert)
head(unlist(error_1),20)
error_2 <- unlist(error_1)
error_2 <- Filter(function(x) {nchar >= 5},error_2)
error_2 <- Filter(function(x) {nchar(x) >= 5},error_2)
error_3 <- grep("^OR-+", error_2,value = T)
head(unlist(error_3),20)
write(unlist(error_3),"alert_testdb.log")
alert <- readLines("oracle_alert_testdb.log")
error_1 <- gsub(" ", "_",alert)
head(unlist(error_1),20)
error_2 <- unlist(error_1)
error_2 <- Filter(function(x) {nchar(x) >= 5},error_2)
error_3 <- grep("^OR-+", error_2,value = T)
error_3 <- grep("^OR-+", error_2, value = T)                 # grep <- find  "^OR 문장의 처음
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
alert <- readLines("oracle_alert_testdb.log")
error_1 <- gsub(" ", "_",alert)
head(unlist(error_1),20)
error_2 <- unlist(error_1)
error_2 <- Filter(function(x) {nchar(x) >= 5},error_2)
error_3 <- grep("^OR-+", error_2, value = T)                 # grep <- find  "^OR 문장의 처음
head(unlist(error_3),20)
write(unlist(error_3),"alert_testdb.log")
library(KoNLP)
library(wordcloud)
library(stringr)
useSejongDic()
setwd("D:/Workspace/R_Data_Analysis/Part2/stage2/Ex01_jeju")
mergeUserDic(data.frame(readLines("제주도여행지.txt"),ncn))
mergeUserDic(data.frame(readLines("제주도여행지.txt"),'ncn''))
mergeUserDic(data.frame(readLines("제주도여행지.txt"),'ncn'))
mergeUserDic(data.frame(readLines("제주도여행지.txt"),"ncn"))
txt <- readLines("jeju.txt")
place <- sapply(txt,extractNoun,USE.NAMES = F)
cdata <- unlist(place)
place <- str_replace_all(cdata, "[^[:alpha:]]","")
place <- gsub(" ", "", place)
txt <- readLines("제주도여행코스gsub.txt")
cnt_txt <- length(txt)
i <- 1
for (i in 1:cnt_txt) {
data3 <- gsub(txt[i],"",place)
}
place <- Filter(function(x) (nchar(x) >= 2),place)
write(unlist(place), "jeju_2.txt")
rev <- read.table('jeju_2.txt')
nrow(rev)
wordcount <- table(rev)
wordcount
head(sort(wordcount, decreasing = T),30)
cnt_txt <- length(txt)
i <- 1
for (i in 1:cnt_txt) {
data3 <- gsub(txt[i],"",place)
}
place <- Filter(function(x) (nchar(x) >= 2),place)
write(unlist(place), "jeju_2.txt")
rev <- read.table('jeju_2.txt')
nrow(rev)
wordcount <- table(rev)
wordcount
head(sort(wordcount, decreasing = T),30)
mergeUserDic(data.frame(readLines("제주도여행지.txt"),"ncn"))
txt <- readLines("jeju.txt")
place <- sapply(txt,extractNoun,USE.NAMES = F)
cdata <- unlist(place)
place <- str_replace_all(cdata, "[^[:alpha:]]","")
place <- gsub(" ", "", place)
txt <- readLines("제주도여행코스gsub.txt")
cnt_txt <- length(txt)
i <- 1
for (i in 1:cnt_txt) {
data3 <- gsub(txt[i],"",place)
}
place <- Filter(function(x) (nchar(x) >= 2),place)
write(unlist(place), "jeju_2.txt")
rev <- read.table('jeju_2.txt')
nrow(rev)
wordcount <- table(rev)
wordcount
head(sort(wordcount, decreasing = T),30)
palete <- brewer.pal(9,"Set1")
mergeUserDic(data.frame(readLines("제주도여행지.txt"),"ncn"))
buildDictionary(data.frame(readLines("제주도여행지.txt"),"ncn"))
buildDictionary(data.frame(readLines("제주도여행지.txt")))
??buildDictionary()
install.packages(Deprecated)
install.packages("Deprecated")
buildDictionary(data.frame(readLines("제주도여행지.txt")))
buildDictionary{data.frame(readLines("제주도여행지.txt"))}
mergeUserDic(data.frame(readLines("제주도여행지.txt")))
txt <- readLines("jeju.txt")
place <- sapply(txt,extractNoun,USE.NAMES = F)
cdata <- unlist(place)
place <- str_replace_all(cdata, "[^[:alpha:]]","")
place <- gsub(" ", "", place)
txt <- readLines("제주도여행코스gsub.txt")
cnt_txt <- length(txt)
i <- 1
for (i in 1:cnt_txt) {
data3 <- gsub((txt[i]),"",place)
}
place <- Filter(function(x) (nchar(x) >= 2),place)
write(unlist(place), "jeju_2.txt")
rev <- read.table('jeju_2.txt')
nrow(rev)
wordcount <- table(rev)
wordcount
head(sort(wordcount, decreasing = T),30)
for (i in 1:cnt_txt) {
place <- gsub((txt[i]),"",place)
}
place <- Filter(function(x) (nchar(x) >= 2),place)
write(unlist(place), "jeju_2.txt")
rev <- read.table('jeju_2.txt')
nrow(rev)
wordcount <- table(rev)
wordcount
head(sort(wordcount, decreasing = T),30)
palete <- brewer.pal(9,"Set1")
top10 <- head(sort(wordcount,decreasing = T),10)
pie(top10,col = brewer.pal("Set3"),radius = 1,main = "제주코스top10")
pie(top10,col = brewer.pal(name="Set3"),radius = 1,main = "제주코스top10")
pie(top10,col = brewer.pal(n=10,name="Set3"),radius = 1,main = "제주코스top10")
pie(top10,col = brewer.pal(n=10,name="RdBu"),radius = 1,main = "제주코스top10")
pct <- round(top10/sum(top10) *100,1)
names(top10)
lab <- paste(names(top10),"\n",pct,"%")
pie(top10,col = brewer.pal(n=10,name="RdBu"),radius = 1,main = "제주코스top10",cex=0.8,labels=lab)
library(ggplot2)
ggplot(top10,aes(top10)) +geom_bar()
ggplot(top10,aes(top10)) + geom_bar()
ggplot(top10,aes(lab)) + geom_bar()
## ggplot draw
str(top10)
df_top10 <- as.data.frame(top10)
df_top10
ggplot(top10,aes(x=rev,y=Freq)) + geom_bar()
ggplot(top10,aes(x=rev,y=Freq)) + geom_bar(stat = "identity")
ggplot(top10,aes(x=rev,y=Freq)) + geom_bar(stat = 'identity')
ggplot(top10,aes(x=,y=Freq)) + geom_bar(stat = 'identity')
ggplot(top10,aes(x='',y=Freq)) + geom_bar(stat = 'identity')
ggplot(df_top10,aes(x='',y=Freq)) + geom_bar(stat = 'identity')
ggplot(df_top10,aes(x='',y=Freq,fill=rev)) + geom_bar(stat = 'identity')
ggplot(df_top10,aes(x='',y=Freq,fill=rev)) + geom_bar(stat = 'identity', width = 1)
ggplot(df_top10,aes(x='',y=freq,fill=rev)) + geom_bar(stat = 'identity', width = 1) + coord_polar("y",start = 0)
ggplot(df_top10,aes(x='',y=Freq,fill=rev)) + geom_bar(stat = 'identity', width = 1) + coord_polar("y",start = 0)
## difficult thing
library(dplyr)
options(digits = 2)
df_top10 <- df_top10 %>%
mutate(pct = Freq /sum(Freq) * 100)
df_top10
mutate(ylable = paste(sprintf("%4.1f",pct), '%',sep = '')
mutate(ypos = cumsum(pct) - 0.5*pct)
df_top10 <- df_top10 %>%
mutate(pct = Freq /sum(Freq) * 100) %>%
mutate(ylable = paste(sprintf("%4.1f",pct), '%',sep = '')) %>%
arrange(desc(rev)) %>%
mutate(ypos = cumsum(pct) - 0.5*pct)
df_top10
ggplot(df_top10, aes(x='',y=Freq,fill=rev)) +
geom_bar(width = 1, stat = 'identity') + coord_polar("y", start = 0)
ggplot(df_top10, aes(x='',y=Freq,fill=rev)) +
geom_bar(width = 1, stat = 'identity') + coord_polar("y", start = 0) +
geom_text(aes(y=ypos,label=ylabel),color='black')
ggplot(df_top10, aes(x='',y=Freq,fill=rev)) +
geom_bar(width = 1, stat = 'identity') + coord_polar("y", start = 0) +
geom_text(aes(y=ypos,label=ylable),color='black')
df_top10 <- df_top10 %>%
mutate(pct = Freq /sum(Freq) * 100) %>%
mutate(ylabel = paste(sprintf("%s\n%4.1f",rev,pct), '%',sep = '')) %>%
arrange(desc(rev)) %>%
mutate(ypos = cumsum(pct) - 0.5*pct)
ggplot(df_top10, aes(x='',y=Freq,fill=rev)) +
geom_bar(width = 1, stat = 'identity') + coord_polar("y", start = 0) +
geom_text(aes(y=ypos,label=ylabel),color='black')
install.packages("extrafont")
library(extrafont)
theme_update(text= element_text(family = "malgun"))
bch <- head(sort(wordcount, decreasing = T),10)
mergeUserDic(data.frame(readLines("제주도여행지.txt")))
txt <- readLines("jeju.txt")
place <- sapply(txt,extractNoun,USE.NAMES = F)
cdata <- unlist(place)
place <- str_replace_all(cdata, "[^[:alpha:]]","")
place <- gsub(" ", "", place)
txt <- readLines("제주도여행코스gsub.txt")
cnt_txt <- length(txt)
i <- 1
for (i in 1:cnt_txt) {
place <- gsub((txt[i]),"",place)
}
place <- Filter(function(x) (nchar(x) >= 2),place)
write(unlist(place), "jeju_2.txt")
rev <- read.table('jeju_2.txt')
nrow(rev)
wordcount <- table(rev)
wordcount
head(sort(wordcount, decreasing = T),30)
palete <- brewer.pal(9,"Set1")
top10 <- head(sort(wordcount,decreasing = T),10)
pie(top10,col = brewer.pal(n=10,name="RdBu"),radius = 1,main = "제주코스top10")
pct <- round(top10/sum(top10) *100,1)
names(top10)
lab <- paste(names(top10),"\n",pct,"%")
pie(top10,col = brewer.pal(n=10,name="RdBu"),radius = 1,main = "제주코스top10",cex=0.8,labels=lab)
## ggplot draw
str(top10)
df_top10 <- as.data.frame(top10)
df_top10
ggplot(df_top10,aes(x='',y=Freq,fill=rev)) + geom_bar(stat = 'identity', width = 1)
ggplot(df_top10,aes(x='',y=Freq,fill=rev)) + geom_bar(stat = 'identity', width = 1) + coord_polar("y",start = 0)
## difficult thing
library(dplyr)
install.packages("extrafont")
library(extrafont)
theme_update(text= element_text(family = "malgun"))
options(digits = 2)          ## 소수점 다음 두자리까지 쓸거야
df_top10 <- df_top10 %>%
mutate(pct = Freq /sum(Freq) * 100) %>%
mutate(ylabel = paste(sprintf("%s\n%4.1f",rev,pct), '%',sep = '')) %>%
arrange(desc(rev)) %>%
mutate(ypos = cumsum(pct) - 0.5*pct)
df_top10
ggplot(df_top10, aes(x='',y=Freq,fill=rev)) +
geom_bar(width = 1, stat = 'identity') + coord_polar("y", start = 0) +
geom_text(aes(y=ypos,label=ylabel),color='black')
##bar chart###
bch <- head(sort(wordcount, decreasing = T),10)
install.packages("extrafont")
bch <- head(sort(wordcount, decreasing = T),10)
mergeUserDic(data.frame(readLines("제주도여행지.txt")))
txt <- readLines("jeju.txt")
place <- sapply(txt,extractNoun,USE.NAMES = F)
cdata <- unlist(place)
place <- str_replace_all(cdata, "[^[:alpha:]]","")
place <- gsub(" ", "", place)
txt <- readLines("제주도여행코스gsub.txt")
cnt_txt <- length(txt)
i <- 1
for (i in 1:cnt_txt) {
place <- gsub((txt[i]),"",place)
}
place <- Filter(function(x) (nchar(x) >= 2),place)
write(unlist(place), "jeju_2.txt")
rev <- read.table('jeju_2.txt')
nrow(rev)
wordcount <- table(rev)
wordcount
head(sort(wordcount, decreasing = T),30)
bch <- head(sort(wordcount, decreasing = T),10)
bch
bp <- barplot(bch, main = "바차트" , col = rainbow, cex.names = 0.7, las = 2, ylim=c(0.25))
bp <- barplot(bch, main = "바차트" , col = rainbow, cex.names = 0.7, las = 2, ylim=c(0,25))
bp <- barplot(bch, main = "바차트" , col = rainbow(), cex.names = 0.7, las = 2, ylim=c(0,25))
bp <- barplot(bch, main = "바차트" , col = "green", cex.names = 0.7, las = 2, ylim=c(0,25))
pct <- round(bch/sum(bch) * 100,1)
bp <- barplot(bch, main = "바차트" , col = rainbow(10), cex.names = 0.7, las = 2, ylim=c(0,25))
text(x = bp, y=bch*1.05,labels = paste("(",pct,"%",")"), col = "black",cex = 0.7)
setwd("D:/Workspace/R_Data_Analysis/Part2/stage2/Ex_hiphop")
hh <- readLines("hiphop.txt")
hh <- readLines("hiphop.txt")
hh
# hiphop.txt 파일을 가지고 다음 문제를 해결하여 파워포인트 파일로 제출하시오.
#
# 1. 워드 클라우드 만들기
# 2. Top 10 단어에 대해서 원 그래프 만들기 (ggplot 사용할 것)
# 3. Top 10 단어에 대해서 막대 그래프 만들기 (ggplot 사용할 것)
# 4. ppt로 작성해서 제출할것
library(dplyr)
library(KoNLP)
library(NLP)
library(stringr)
useSejongDic()
library(wordcloud2)
hh <- sapply(hh, extractNoun,USE.NAMES = F)
hh
library(tm)
hh <- readLines("hiphop.txt")
hh
hh <- sapply(hh, extractNoun,USE.NAMES = F)
hh
corp1 <- Corpus(VectorSource(hh))
hh <- readLines("hiphop.txt")
hh
corp1 <- Corpus(VectorSource(hh))
corp1
inspect(corp1)
tdm <- TermDocumentMatrix(corp1)
tdm
m <- as.matrix(tdm)
m
corp2 <- tm_map(corp1, stripWhitespace)
corp2 <- tm_map(corp2, tolower)
corp2 <- tm_map(corp1, removeNumbers)
corp2 <- tm_map(corp2, removeNumbers)
corp2 <- tm_map(corp2, PlainTextDocument)
sword2 <- c(stopwords('en'), "and","but","not")
corp2 <- tm_map(corp2, removeWords,sword2)
tdm2 <- TermDocumentMatrix(corp2)
corp2
View(corp2)
hh <- readLines("hiphop.txt")
hh
hh <- sapply(hh, extractNoun, USE.NAMES = F)
hh
hh <- Filter(function(x) {nchar(x) >= 2},hh)
hh
hh <- Filter(function(x) {nchar(x) >= 2},hh)
hh
hh <- Filter(function(x) {nchar(x) >= 2},hh)
hh
View(hh)
hh <- readLines("hiphop.txt")
hh
hh <- sapply(hh, extractNoun, USE.NAMES = F)
hh
wordcount <- table(hh)
unlist(hh)
uhh <- unlist(hh)
wordcount <- table(uhh)
wordcount
nrow(uhh)
hh <- readLines("hiphop.txt")
corp1 <- Corpus(VectorSource(hh))
corp1
inspect(corp1)
corp2 <- tm_map(corp1, stripWhitespace)
corp2 <- tm_map(corp2, tolower)
corp2 <- tm_map(corp2, removeNumbers)
corp2 <- tm_map(corp2, PlainTextDocument)
sword2 <- c(stopwords('en'), "and","but","not")
corp2 <- tm_map(corp2, removeWords,sword2)
corp2
View(corp2)
chh <- sapply(corp2, extractNoun, USE.NAMES = F)
chh <- sapply(corp2, extractNoun, USE.NAMES = FALSE)
chh <- sapply(corp2, extractNoun, USE.NAMES == FALSE)
hh <- readLines("hiphop.txt")
corp2 <- tm_map(hh, stripWhitespace)
hh <- readLines("hiphop.txt")
chh <- unlist(hh)
hh1 <- str_replace_all(hh1, "[^[:alpha:]]","")
hh1 <- str_replace_all(chh, "[^[:alpha:]]","")
hh1
hh1 <- str_replace_all(chh, "[^[:alpha:]]","")
hh1
hh <- readLines("hiphop.txt")
chh <- sapply(hh, extractNoun, USE.NAMES == FALSE)
uhh <- unlist(chh)
hh1 <- str_replace_all(uhh, "[^[:alpha:]]","")
hh1
hh <- readLines("hiphop.txt")
chh <- sapply(hh, extractNoun, USE.NAMES == FALSE)
uhh <- unlist(chh)
View(uhh)
hh <- readLines("hiphop.txt")
hh <- sapply(hh, extractNoun, USE.NAMES == FALSE)
uhh <- unlist(hh)
uhh
hh <- Filter(function(x) {nchar(x) >= 2},hh)
hh
hh <- Filter(function(x) {nchar(x) >= 2},uhh)
fhh <- Filter(function(x) {nchar(x) >= 2},uhh)
fhh
hh <- readLines("hiphop.txt")
hh <- sapply(hh, extractNoun, USE.NAMES == FALSE)
uhh <- unlist(hh)
fhh <- Filter(function(x) {nchar(x) >= 2},uhh)
wordcount <- table(fhh)
wordcount
hh <- readLines("hiphop.txt")
hh <- sapply(hh, extractNoun, USE.NAMES == FALSE)
hh
corp1 <- Corpus(VectorSource(hh))
corp2 <- tm_map(corp1, stripWhitespace)
corp2 <- tm_map(corp2, tolower)
corp2 <- tm_map(corp2, removeNumbers)
corp2 <- tm_map(corp2, PlainTextDocument)
sword2 <- c(stopwords('en'), "and","but","not")
corp2 <- tm_map(corp2, removeWords,sword2)
corp2
corp3 <- TermDocumentMatrix(corp2, control = list(wordLength=c(1,Inf)))
corp3 <- TermDocumentMatrix(corp2)
hh <- readLines("hiphop.txt")
corp1 <- Corpus(VectorSource(hh))
corp2 <- tm_map(corp1, stripWhitespace)
corp2 <- tm_map(corp2, tolower)
corp2 <- tm_map(corp2, removeNumbers)
corp2 <- tm_map(corp2, PlainTextDocument)
sword2 <- c(stopwords('en'), "and","but","not")
corp2 <- tm_map(corp2, removeWords,sword2)
corp2
tdm <- TermDocumentMatrix(corp2)
View(corp2)
